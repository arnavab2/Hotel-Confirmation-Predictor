{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kxMOfmBosXPp",
        "_xLJLhgAsnVM",
        "5-uQprbks2bf"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Setup"
      ],
      "metadata": {
        "id": "kxMOfmBosXPp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gCCE6A31xcmS"
      },
      "outputs": [],
      "source": [
        "### FILE DATA FOR TRAINING\n",
        "\n",
        "# Train_Filename: Filepath for the training data. Training data is represented in Z-scores based on given distribution\n",
        "TRAIN_FILENAME = '/content/drive/MyDrive/Reservations_Final1.csv'\n",
        "\n",
        "# Target_Col:'Y' column, translated to Z-scores\n",
        "TARGET_COL = 'canceled'\n",
        "\n",
        "# Metric = Most important metric to sort by\n",
        "METRIC = \"AUC\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycaret\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.utils import resample\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "61gipcH0zyAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Input Dataframe\n",
        "path= TRAIN_FILENAME\n",
        "df=pd.read_csv(path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARSQ30ah0ElJ",
        "outputId": "dedfc38e-cb31-4f4a-f869-c375b2aef488"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Undersampling"
      ],
      "metadata": {
        "id": "_xLJLhgAsnVM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate input features and target\n",
        "y = df.canceled\n",
        "X = df.drop('canceled', axis=1)\n",
        "\n",
        "# setting up testing and training sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=27)\n",
        "\n",
        "# concatenate our training data back together\n",
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "test = pd.concat([X_test, y_test], axis=1)\n",
        "\n",
        "\n",
        "# separate minority and majority classes\n",
        "not_canc = train[train.canceled==0]\n",
        "canc = train[train.canceled==1]\n",
        "\n",
        "# upsample minority\n",
        "upsampled = resample(not_canc,\n",
        "                          replace=True, # sample with replacement\n",
        "                          n_samples=len(canc), # match number in majority class\n",
        "                          random_state=27) # reproducible results\n",
        "\n",
        "# combine majority and upsampled minority\n",
        "newdf = pd.concat([canc, upsampled])"
      ],
      "metadata": {
        "id": "ASnd9zff0IOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Optimization"
      ],
      "metadata": {
        "id": "5-uQprbks2bf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop na rows for hyperparameter optimization\n",
        "newdf.dropna(inplace=True)\n",
        "test.dropna(inplace=True)\n",
        "\n",
        "# check new class counts\n",
        "print(len(newdf), len(test))\n",
        "\n",
        "# split training and test data again\n",
        "y_train = newdf.canceled\n",
        "X_train = newdf.drop('canceled', axis=1)\n",
        "\n",
        "y_test = test.canceled\n",
        "X_test = test.drop('canceled', axis=1)\n",
        "\n",
        "# create options in hyperparameter optimization grid\n",
        "hp_grid = {'n_estimators': [64, 80, 96, 100, 112, 128],\n",
        "               'max_features': [\"sqrt\", \"log2\"],\n",
        "               'min_samples_split': [2, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "               'min_samples_leaf': [1, 0.1, 0.125, 0.15, 0.175, 0.2]}\n",
        "\n",
        "# Training Classifiers depending on metric\n",
        "tuned_rf_auc = GridSearchCV(estimator=RandomForestClassifier(), param_grid=hp_grid, scoring='roc_auc')\n",
        "tuned_rf_accuracy = GridSearchCV(estimator=RandomForestClassifier(), param_grid=hp_grid, scoring='accuracy')\n",
        "tuned_rf_recall = GridSearchCV(estimator=RandomForestClassifier(), param_grid=hp_grid, scoring='recall')"
      ],
      "metadata": {
        "id": "bC_2qQ6FeN41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimize for auc\n",
        "print(\"AUC\")\n",
        "tuned_rf_auc.fit(X_train, y_train) \n",
        "print(tuned_rf_auc.best_params_) \n",
        "pred_auc = tuned_rf_auc.predict(X_test) \n",
        "print(classification_report(y_test, pred_auc))"
      ],
      "metadata": {
        "id": "_X8u_bMNHboH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimize accuracy\n",
        "print(\"Accuracy\")\n",
        "tuned_rf_accuracy.fit(X_train, y_train) \n",
        "print(tuned_rf_accuracy.best_params_) \n",
        "pred_accuracy = tuned_rf_accuracy.predict(X_test) \n",
        "print(classification_report(y_test, pred_accuracy))"
      ],
      "metadata": {
        "id": "YWxpHuL-r4NL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# optimize recall\n",
        "print(\"Recall\")\n",
        "tuned_rf_recall.fit(X_train, y_train) \n",
        "print(tuned_rf_recall.best_params_) \n",
        "pred_recall = tuned_rf_recall.predict(X_test) \n",
        "print(classification_report(y_test, pred_recall))"
      ],
      "metadata": {
        "id": "x4NssKOGr58F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}